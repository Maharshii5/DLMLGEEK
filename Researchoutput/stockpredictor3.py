# -*- coding: utf-8 -*-
"""Stockpredictor3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oAHxyid8svzpo030TBdOiZcMWvBdnEQm
"""

pip install yfinance pandas numpy tensorflow scikit-learn

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import matplotlib.pyplot as plt
from prophet import Prophet

stock_symbols = ['RELIANCE.NS', 'TCS.NS', 'INFY.NS']  # Add more as needed

# Dictionary to store predictions for each company
company_predictions = {}

for symbol in stock_symbols:
    # Step 1: Load and Preprocess Data
    data = yf.download(symbol, start='2015-01-01', end='2025-01-01')
    close_prices = data['Close'].values

    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(close_prices.reshape(-1, 1))

    # Step 2: Prepare Training Data
    train_data_len = int(np.ceil(len(scaled_data) * 0.8))
    train_data = scaled_data[0:int(train_data_len), :]

    x_train, y_train = [], []
    for i in range(60, len(train_data)):
        x_train.append(train_data[i-60:i, 0])
        y_train.append(train_data[i, 0])

    x_train, y_train = np.array(x_train), np.array(y_train)
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

    # Step 3: Build the LSTM Model
    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)),
        Dropout(0.2),
        LSTM(50, return_sequences=False),
        Dropout(0.2),
        Dense(25),
        Dense(1)
    ])

    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(x_train, y_train, batch_size=64, epochs=50)

    # Step 4: Future Prediction using Facebook Prophet
    prophet_data = data.reset_index()[['Date', 'Close']]
    prophet_data.columns = ['ds', 'y']  # Rename for Prophet requirements

# Remove timezone information
    prophet_data['ds'] = pd.to_datetime(prophet_data['ds']).dt.tz_localize(None)

# Initialize and fit Prophet model
    prophet = Prophet()
    prophet.fit(prophet_data)

    future_dates = prophet.make_future_dataframe(periods=30)  # Predict 30 days into the future
    forecast = prophet.predict(future_dates)

    # Store and plot predictions
    company_predictions[symbol] = forecast[['ds', 'yhat']].tail(30)  # Only store future predictions
    forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].plot(x='ds', y='yhat', label=symbol)
    plt.title(f'{symbol} Stock Price Forecast')
    plt.xlabel('Date')
    plt.ylabel('Predicted Close Price')
    plt.legend()
    plt.show()

# Step 5: Access predictions for each company in the dictionary
for symbol, predictions in company_predictions.items():
    print(f"Future predictions for {symbol}:\n", predictions)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import yfinance as yf
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split

# Load historical stock data for a specific company
ticker = 'TCS.NS'  # Example: Reliance Industries Limited
data = yf.download(ticker, start='2010-01-01', end='2025-01-01')

# Preprocess the data
data = data[['Close']]
data = data.values
data = data.astype('float32')

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Create a dataset
def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset) - time_step):
        X.append(dataset[i:(i + time_step), 0])
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 60  # Look back 60 days
X, y = create_dataset(data_scaled, time_step)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Train XGBoost model
model_xgb = XGBRegressor(objective='reg:squarederror')
model_xgb.fit(X_train, y_train)

# Get predictions
predictions = model_xgb.predict(X_test)
predictions = scaler.inverse_transform(predictions.reshape(-1, 1))  # Inverse the scaling

# Calculate RMSE, MAE, and R²
rmse = np.sqrt(mean_squared_error(y_test, predictions))
mae = mean_absolute_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

# Print the metrics
print(f'RMSE: {rmse:.2f}')
print(f'MAE: {mae:.2f}')
print(f'R² Score: {r2:.2f}')

# Plotting the results
plt.figure(figsize=(14, 5))
plt.plot(data[len(data) - len(predictions):], label='Actual Prices', color='blue')
plt.plot(predictions, label='Predicted Prices', color='red')
plt.title(f'Stock Price Prediction for {ticker} using XGBoost\n'
          f'RMSE: {rmse:.2f}, MAE: {mae:.2f}, R² Score: {r2:.2f}')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import yfinance as yf



# Preprocess the data
ticker = 'TCS.NS'  # Example: Reliance Industries Limited
data = yf.download(ticker, start='2010-01-01', end='2024-10-31')
print(data.head())  # Print the first few rows of the data
print(data.shape)

# Preprocess the data


# Normalize the data

data = data[['Close']]
data = data.values
data = data.astype('float32')

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Create a dataset
X, y = create_dataset(data_scaled, time_step)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Train Random Forest model
model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
model_rf.fit(X_train, y_train)

# Get predictions
predictions = model_rf.predict(X_test)
predictions = scaler.inverse_transform(predictions.reshape(-1, 1))  # Inverse the scaling

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_test, predictions))
rmse = np.sqrt(mean_squared_error(y_test, predictions))
mae = mean_absolute_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

# Print the metrics
print(f'RMSE: {rmse:.2f}')
print(f'MAE: {mae:.2f}')
print(f'R² Score: {r2:.2f}')

# Plotting the results
plt.figure(figsize=(14, 5))
plt.plot(data[len(data) - len(predictions):], label='Actual Prices', color='blue')
plt.plot(predictions, label='Predicted Prices', color='red')
plt.title(f'Stock Price Prediction for {ticker} using Random Forest (RMSE: {rmse:.2f})')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import yfinance as yf
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout

# Load historical stock data for a specific company
ticker = 'RELIANCE.NS'  # Example: Reliance Industries Limited
data = yf.download(ticker, start='2010-01-01', end='2025-01-01')

# Preprocess the data
data = data[['Close']]
data = data.values
data = data.astype('float32')

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Create a training dataset
train_size = int(len(data_scaled) * 0.8)
train_data = data_scaled[:train_size]

# Prepare the data for LSTM
def create_dataset(dataset, time_step=1):
    X, Y = [], []
    for i in range(len(dataset) - time_step - 1):
        X.append(dataset[i:(i + time_step), 0])
        Y.append(dataset[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 60  # Look back 60 days
X_train, y_train = create_dataset(train_data, time_step)
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=50, batch_size=32)

# Create the test dataset
test_data = data_scaled[train_size - time_step:]
X_test, y_test = create_dataset(test_data, time_step)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Get predictions
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)  # Inverse the scaling

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_test, predictions))

# Plotting the results
plt.figure(figsize=(14, 5))
plt.plot(data[len(data) - len(predictions):], label='Actual Prices', color='blue')
plt.plot(predictions, label='Predicted Prices', color='red')
plt.title(f'Stock Price Prediction for {ticker} (RMSE: {rmse:.2f})')
plt.xlabel('Days')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

pip install prophet